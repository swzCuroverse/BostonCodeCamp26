{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring NYC Housing Costs, An Introduction to Python for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This demo uses a data set available from NYC Open Data (https://nycopendata.socrata.com/) to showcase how to use python for data science. In particular, it will be focused on loading tabular data, data munging, plotting, calculating descriptive statistics, modeling data, and working with time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "%matplotlib inline  \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Polygon\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1) Introducing Data Frames (Importing, Indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading in a single Excel file into a data frame using pandas. This is just one of the files\n",
    "# we will need to reed in.  Let's read it in as a test. Note: file has a 4 line header.\n",
    "\n",
    "dataTest = pd.read_excel('Datafiles/2009_brooklyn.xls', header=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Displaying lines from data frame (note: columns are labeled from data in file)\n",
    "\n",
    "dataTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There are multiple ways to index into a pandas data frame.\n",
    "# You can index an entire column using the dot notation.\n",
    "\n",
    "dataTest.ADDRESS  # also can use data['ADDRESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can retrieve specific columns and rows using .ix. This is flexible because ix supports both \n",
    "# label and integer position indexing. However, this can get confusing if you use integers to label either your\n",
    "# rows for columns.  If you want to specify that you are  only using labels, you can index using .loc and if you \n",
    "# you want to only integer positions then you an use .iloc. \n",
    "\n",
    "dataTest.ix[:5,'ADDRESS']  # note this indexing will return a data frame or series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you want the underlying value in a data frame - you can use .values\n",
    "\n",
    "dataTest.ix[:5,'ADDRESS'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting list of housing files to import\n",
    "\n",
    "fileList = listdir('Datafiles')   # getting files/directories in the folder\n",
    "fileListHousing = [x for x in fileList if '.xls' in x]  # extracting file names that contain .xls\n",
    "\n",
    "fileListHousing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pandas automatically reads in our column names from the line following the header lines. We can use that\n",
    "# fact to determine if our file either has a 4 or a 3 line header\n",
    "\n",
    "dataTest.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataAll = pd.DataFrame()\n",
    "\n",
    "# Loop through all files and append to precious read in data. Files either have a header of 3 lines of 4 lines. \n",
    "# To work around this, we try 4 header lines.  If that does not work, we use 3 header lines.\n",
    "\n",
    "for file in fileListHousing:\n",
    "    dataRead = pd.read_excel('Datafiles/' + file, header=4) \n",
    "    if dataRead.columns.values[0] != 'BOROUGH':\n",
    "        dataRead = pd.read_excel('Datafiles/' + file, header=3)  \n",
    "    dataAll = dataAll.append(dataRead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Cleaning and Plotting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pandas has built-in statistical methods that work directly on data frames. \n",
    "# Here is a handy list in the documenation:\n",
    "\n",
    "dataAll.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleaning the data by removing the NaNs and unrealistic values for other variables. \n",
    "# Note: you use DataFrame.clip, if you want to threshhold your data\n",
    "\n",
    "dataClean = dataAll.dropna(subset ={'SALE PRICE'})\n",
    "\n",
    "idx = dataClean['SALE PRICE'] > 1000  \n",
    "idx2 = dataClean['LAND SQUARE FEET'] > 0  \n",
    "idx3 = dataClean['GROSS SQUARE FEET'] > 0  \n",
    "idx4 = dataClean['RESIDENTIAL UNITS'] ==  1\n",
    "idx5 = dataClean['COMMERCIAL UNITS'] ==  0\n",
    "idx6 = dataClean['BOROUGH'] > 0\n",
    "idx7 = dataClean['ZIP CODE'] > 0 \n",
    "\n",
    "dataClean['ZIP CODE'] = dataClean['ZIP CODE'].apply(str)  # make zipcode into a string\n",
    "\n",
    "dataClean  = dataClean[idx & idx2 & idx3 & idx4  & idx5 & idx6 & idx7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply function to a column.  There are build in functions that automatically work with data frames.  If you\n",
    "# do not specify a column, the function will be run on the entire data frame, where possible.\n",
    "\n",
    "dataClean['SALE PRICE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can use apply to apply a function to a column when it is not supported directly on a data frame. Can add\n",
    "# the resuling column to a data frame. \n",
    "\n",
    "dataClean['LOG PRICE'] = dataClean['SALE PRICE'].apply(np.log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Built in plotting is available for data frames.  This is an easy (quick & dirty) way to view your data. \n",
    "# You can make more elaborate or publication quality graphs by using matplotlib or seaborn directily. \n",
    "\n",
    "dataClean['LOG PRICE'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Draw a boxplot with a narrower bandwidth than the default\n",
    "ax = sns.boxplot(data=dataClean, x='BOROUGH', y='SALE PRICE')\n",
    "ax.set_yscale(\"log\")\n",
    "bNames = ['Manhattan','Bronx','Brooklyn','Queens','Staten Island']\n",
    "ax.set_xticklabels(bNames);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Grouping and Reshaping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grouping allows you to apply functions to a group of data.  In this case, let's look at mean price by zipcode. \n",
    "\n",
    "grpBorough = dataClean.groupby(by='BOROUGH')\n",
    "byBorough = grpBorough['SALE PRICE'].describe()\n",
    "byBorough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Can unstack the data (similar to using some functionality of pivot tables in Excel), Stacking is also \n",
    "# available as well as the method pivot_table with allows for full pivot table functionality \n",
    "\n",
    "byBorough.unstack(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Creating Geographical Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For reference here is map of NYC with boroughs labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/New_York_City_District_Map_2.png\",width=200,height=200>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting mean price on a map of Brooklyn\n",
    "# Calculating mean price by zipcode\n",
    "\n",
    "grpZip = dataClean.groupby(by='ZIP CODE')\n",
    "meanByZip = grpZip['SALE PRICE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the base map\n",
    "fig, ax2 = plt.subplots(1,1,figsize=(12, 12))\n",
    "m = Basemap(llcrnrlon=-74.5,llcrnrlat=40.45,urcrnrlon=-73.5,urcrnrlat=40.95,\n",
    "            projection='lcc',lat_1=39.5,lat_2=41,lon_0=-74)\n",
    "\n",
    "# Read in the zipcode map shapefile\n",
    "shp_info = m.readshapefile(cwd + '/Mapfiles/cb_2013_us_zcta510_500k','zipCode',drawbounds= True, linewidth = 0.05)\n",
    "\n",
    "# Getting a list of zip codes we want to plot\n",
    "zipcode_list = meanByZip.index.values\n",
    "zipcode_list = zipcode_list.tolist()\n",
    "\n",
    "# Setting the colormap\n",
    "cmap = plt.cm.get_cmap('viridis')  # by default levels 0-256\n",
    "\n",
    "cindex= []\n",
    "zipcodes = []\n",
    "\n",
    "# Calculating the max, min log sale price values, will be used to normalize price to index into colorscale\n",
    "maxZip = np.float64(meanByZip.values.max())\n",
    "maxZipLog = np.log10(maxZip)\n",
    "minZip = np.float64(meanByZip.values.min())\n",
    "minZipLog = np.log10(minZip)\n",
    "\n",
    "# Find zipcodes for new shape in shape file\n",
    "for shapedict in m.zipCode_info:\n",
    "    # cycle through zipcode\n",
    "    zipcode = shapedict['ZCTA5CE10']\n",
    "    zipcodes.append(zipcode)\n",
    "\n",
    "ax1 = plt.gca() # get current axes instance\n",
    "\n",
    "# For each shape in shape file, plot polygon segments.  Color is picked by indexing into colormap using\n",
    "# normalized cost, colormap by default has 256 levels,\n",
    "\n",
    "for nshape,seg in enumerate(m.zipCode):\n",
    "    if zipcodes[nshape] in zipcode_list:\n",
    "        cost = np.log10(meanByZip.loc[zipcodes[nshape]])\n",
    "        cindex = int(((cost - minZipLog)/(maxZipLog - minZipLog))*257)\n",
    "        color = cmap(cindex)[:3]\n",
    "        poly = Polygon(seg,facecolor = color,  edgecolor= 'k')\n",
    "        ax1.add_patch(poly)\n",
    "        \n",
    "plt.title('Mean 1-Bedroom House Prices: 2003-2009')       \n",
    "\n",
    "# Create a scaled colorbar that gives the range of values\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "sm.set_array(np.linspace(minZipLog,maxZipLog,257))\n",
    "cb = plt.colorbar(sm, shrink=.5, pad = 0.1)\n",
    "cb.ax.set_title('Log10 of Sale Price');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Merging Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merging New Data into out DataSet\n",
    "\n",
    "# Let's load in population and plot that verus mean price per zipcode\n",
    "# Unlike before, let's specify zip code as a string and not a number.\n",
    "\n",
    "popData = pd.read_csv('Datafiles/2010Census.csv',dtype = {'Zip Code ZCTA':str})\n",
    "popData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meanbyZip2 =  grpZip.mean()\n",
    "\n",
    "meanAllbyZip = meanbyZip2.merge(popData,how='inner', left_index='TRUE', right_on='Zip Code ZCTA')\n",
    "meanAllbyZip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can make a scatter plot to see the influence of population on housing prices for the different boroughs\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8, 4))\n",
    "cmp = plt.cm.get_cmap('Set2',5)\n",
    "\n",
    "ax.scatter(meanAllbyZip['2010 Census Population'], meanAllbyZip['SALE PRICE'],c = meanAllbyZip['BOROUGH'], \n",
    "           s = 80, cmap = cmp,alpha = 0.5)\n",
    "\n",
    "ax.set_title('Sale Price vs Population (Average by Zip Code)');\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim([0,120000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Working with Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So far we have dealt with our data as if does not have a time component, if we use the date of purchase as the \n",
    "# index, we can use our data frame like a timeseries. \n",
    "\n",
    "# First, we need to convert our SALE DATA to a datetime \n",
    "\n",
    "dataClean['SALE DATE'] = pd.to_datetime(dataClean['SALE DATE'])\n",
    "\n",
    "# Next, set SALE DATE as our index.  And now we can use the data frame as a time series. \n",
    "\n",
    "dataTime = dataClean.set_index(dataClean['SALE DATE'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can now index using a date, or range of dates\n",
    "\n",
    "dataTime['2004-12-01':'2005-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can also resample (and apply a function to the data in the sample window). In this\n",
    "# case let's resample every month, and get the mean price.\n",
    "\n",
    "dataTimebyMonth = dataTime['SALE PRICE'].resample('1m').mean()\n",
    "dataTimebyMonth[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We actually want this divided by borough. So, we can group and then apply our resampling. \n",
    "\n",
    "dataCTbyBorough = dataTime.groupby('BOROUGH')\n",
    "\n",
    "g = lambda x: x.resample('1m').mean()  # define anonymous function to resample each group of data \n",
    "\n",
    "# Or could define a regular function ....\n",
    "\n",
    "def galt(x):\n",
    "    xresample = x.resample('1m').mean()\n",
    "    return xresample\n",
    "\n",
    "# Apply function to each group\n",
    "\n",
    "#salebyMonth = dataCTbyBorough['SALE PRICE'].apply(galt)\n",
    "\n",
    "salebyMonth = dataCTbyBorough['SALE PRICE'].apply(g)\n",
    "salebyMonth = salebyMonth.unstack(0)  # unstack so we have time as the rows and borough as the columns\n",
    "\n",
    "salebyMonth[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot results, timeseries data frames are supported by the built-in plot method.  \n",
    "# Note that the build in methods do offer several options for customization. \n",
    "\n",
    "f, ax4 = plt.subplots(1,1,figsize=(8, 4))\n",
    "salebyMonth.plot(ax = ax4, logy = True, title = 'Mean Sale Price in Time', colormap = 'Dark2')\n",
    "ax4.legend(labels=bNames,loc = 'upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Modeling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are many different ways to model this data.  There is clearly a time component. For the sake of \n",
    "# simplicity since this demo is focused on showing how to use the functionality and on the getting the BEST model, \n",
    "# we are just going to take data from a fixed year (2009)\n",
    "\n",
    "# Extracting data from 2009\n",
    "data2009 = dataTime['2009-01-01':'2009-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's clean out the variables that are constant (Commerical Units, etc) and keep variables that may be of\n",
    "# importance to our model. For simplicity again, we are going to consider Borough, Zipcode, Land Square Feet, \n",
    "# Gross Square Feet\n",
    "\n",
    "Xtotal = data2009.ix[:,{'BOROUGH','ZIP CODE','GROSS SQUARE FEET','LAND SQUARE FEET'}]\n",
    "ytotal = data2009.ix[:,{'LOG PRICE'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to treat as categorical variables, since even though\n",
    "# they are numbers, they represent categories and not numbers (i.e. 1 isn't greater than 5 for borough). Pandas\n",
    "# can let us convert them to dummy variables (convert using onehot encoding). \n",
    "\n",
    "XtotalDMY = pd.get_dummies(Xtotal, columns={'BOROUGH','ZIP CODE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XtotalDMY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardize our data. \n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(XtotalDMY)\n",
    "Xscaled = scaler.transform(XtotalDMY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fitting the data using linear regression, then plotting the test data vs the predicted values. \n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xscaled, ytotal, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "predicted = regr.predict(X_test)\n",
    "             \n",
    "f, ax = plt.subplots(1,1,figsize=(8, 4))\n",
    "ax.scatter(y_test, predicted)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fitting the data using random forest, then plotting the test data vs the predicted values. In\n",
    "# this case we are using defaults for our random forest, but there is a nice example on how to tweak\n",
    "# the values for best performace for your particular data here--\n",
    "# http://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html#sphx-glr-auto-examples-ensemble-plot-ensemble-oob-py\n",
    "\n",
    "regr_rf = RandomForestRegressor() \n",
    "regr_rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict on new data\n",
    "predicted_rf = regr_rf.predict(X_test)\n",
    "\n",
    "f, ax = plt.subplots(1,1,figsize=(8, 4))\n",
    "ax.scatter(y_test, predicted_rf)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
